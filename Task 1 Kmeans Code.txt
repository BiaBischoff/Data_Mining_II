#Importing Libraries
import pandas as pd
import numpy as np
import seaborn as sns

import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

# Libraries for Visualization Purposes
import matplotlib.pyplot as plt
# from scipy.spatial.distance import cdist

#Scipy
from scipy.cluster.vq import kmeans, vq

# Loading the Churn Dataset
churn_df = pd.read_csv('/Users/bia/Desktop/Datasets for D212/churn_clean.csv')

#Dataset Size with SHAPE
print(churn_df.shape)

#Dataset columns
print(churn_df.columns)

#Dataset Info
print(churn_df.info)

#Dataset Columns Types
print(churn_df.dtypes)

#Basic Stats of the data
print(churn_df.describe())

#Removing some unecessary columns
churn_df = churn_df.drop(columns=['CaseOrder', 'Customer_id', 'Interaction', 'UID'])

#Renaming Customer Survey Answers (Item1 to Item8)
churn_df.rename(columns={'Item1':'TimelyResponse', 'Item2':'Fixes', 'Item3':'Replacements',
                         'Item4':'Reliability', 'Item5':'Options', 'Item6':'Respectfulness',
                         'Item7':'Courteous', 'Item8':'Listening'}, inplace=True)

#Checking if my changes were in place
print(churn_df.head())

# #Histogram for Numerical Data
# dataset = churn_df[['MonthlyCharge', 'Bandwidth_GB_Year', 'Yearly_equip_failure', 'Children', 'Age', 'Income',
#                     'Outage_sec_perweek','Email', 'Contacts', 'Tenure']]
# fig = plt.figure(figsize=(15, 12))
# plt.suptitle('Histograms - Numerical Data \n', horizontalalignment="center", fontstyle="normal", fontsize=24,
#              fontfamily="sans-serif")
# for i in range(dataset.shape[1]):
#     plt.subplot(6, 3, i + 1)
#     f = plt.gca()
#     f.set_title(dataset.columns.values[i])
#     vals = np.size(dataset.iloc[:, i].unique())
#     if vals >= 100:
#         vals = 100
#     plt.hist(dataset.iloc[:, i], bins=vals, color='#ec838a')
# plt.tight_layout(rect=[0, 0.03, 1, 0.95])
# plt.show()

# #Scatter Matrix
# churn_num = churn_df[['MonthlyCharge', 'Bandwidth_GB_Year', 'Yearly_equip_failure', 'Children', 'Age', 'Income',
#                     'Outage_sec_perweek','Email', 'Contacts', 'Tenure']]
# scatter_matrix = pd.plotting.scatter_matrix(churn_num, figsize = [15,15], diagonal = "kde", color = "magenta")
#
# for ax in scatter_matrix.ravel():
#     ax.set_xlabel(ax.get_xlabel(), fontsize = 10, rotation = 90)
#     ax.set_ylabel(ax.get_ylabel(), fontsize = 10, rotation = 0)
# plt.title('Scatter Matrix')
# plt.show()
#
# #Create dataframe for heatmap bivariate analysis of correlation
# churn_bivariate = churn_df[['MonthlyCharge', 'Bandwidth_GB_Year', 'Churn', 'Multiple', 'Tenure', 'Outage_sec_perweek']]
# sns.heatmap(churn_bivariate.corr(), annot=True)
# plt.show()
#
# # Create Seaborn boxplots for continuous variables
# sns.boxplot('MonthlyCharge', data = churn_df)
# plt.show()
# print("MonthlyCharge Stats are: ", churn_df.MonthlyCharge.describe())
#
# # Create Seaborn boxplots for continuous variables
# sns.boxplot('Bandwidth_GB_Year', data = churn_df)
# plt.show()
# print("Bandwidth_GB_Year Stats are: ", churn_df.Bandwidth_GB_Year.describe())
#
# # Create Seaborn boxplots for continuous variables
# sns.boxplot('Age', data = churn_df)
# plt.show()
# print("Age Stats are: ", churn_df.Age.describe())
#
# # Create Seaborn boxplots for continuous variables
# sns.boxplot('Tenure', data = churn_df)
# plt.show()
# print("Tenure Stats are: ", churn_df.Tenure.describe())

# #Finding missing values in my dataset
# churn_df.isnull().any(axis=1)
# null_values = churn_df.isna().any()
# print(null_values)

# print(churn_df['Contract'].unique())

#Transforming Categorical Data into Numerical Data
#Changing Variables from NO/YES to 0/1
churn_df.Churn.replace({"Yes":1, "No":0}, inplace = True)
churn_df.Phone.replace({"Yes":1, "No":0}, inplace = True)
churn_df.PaperlessBilling.replace({"Yes":1, "No":0}, inplace = True)
churn_df.Techie.replace({"Yes":1, "No":0}, inplace = True)
churn_df.Port_modem.replace({"Yes":1, "No":0}, inplace = True)
churn_df.Tablet.replace({"Yes":1, "No":0}, inplace = True)
churn_df.Multiple.replace({"Yes":1, "No":0}, inplace = True)
churn_df.OnlineSecurity.replace({"Yes":1, "No":0}, inplace = True)
churn_df.OnlineBackup.replace({"Yes":1, "No":0}, inplace = True)
churn_df.DeviceProtection.replace({"Yes":1, "No":0}, inplace = True)
churn_df.TechSupport.replace({"Yes":1, "No":0}, inplace = True)
churn_df.StreamingTV.replace({"Yes":1, "No":0}, inplace = True)
churn_df.StreamingMovies.replace({"Yes":1, "No":0}, inplace = True)

#Creating a dummy variable for some of the categorical variables with 3 or more levels
dummy1 = pd.get_dummies(churn_df[['Marital', 'Contract', 'PaymentMethod', 'Gender', 'InternetService', 'Area']])

#Adding the results to the master dataframe
churn_df = pd.concat([churn_df, dummy1], axis=1)

#We have created dummies for the below variables, so we can drop them
churn_df = churn_df.drop(['Marital', 'Contract', 'PaymentMethod', 'Gender', 'InternetService', 'Area'], 1)

#Extract the "Prepared"" dataset
churn_df.to_csv('prepared_churn_data_kmeans.csv')
churn_df = pd.read_csv('prepared_churn_data_kmeans.csv')
df = churn_df.columns
print('The dataset columns are ', df)

#Starting the KMeans Analysis
df = pd.read_csv('prepared_churn_data_kmeans.csv', index_col= 0)

#Importing KMeans
from sklearn.cluster import KMeans

#Selecting ggplot to make it look pretty
plt.style.use('ggplot')

#Selecting the features Tenure and MonthlyCharge (They are respectively columns number 30 and 31)
X = churn_df.iloc[:,[30,31]].values
#Selecting the features Income and MonthlyCharge
# X = churn_df.iloc[:,[12,31]].values
#Selecting the features Tenure and Bandwidth
# X = churn_df.iloc[:,[30,32]].values




# distortions = []
# inertias = []
# mapping1 = {}
# mapping2 = {}
# K = range(1, 10)
#
# for k in K:
# 	# Building and fitting the model
# 	kmeanModel = KMeans(n_clusters=k).fit(X)
# 	kmeanModel.fit(X)
#
# 	distortions.append(sum(np.min(cdist(X, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / X.shape[0])
# 	inertias.append(kmeanModel.inertia_)
#
# 	mapping1[k] = sum(np.min(cdist(X, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / X.shape[0]
# 	mapping2[k] = kmeanModel.inertia_
#
# for key, val in mapping1.items():
#     print(f'{key} : {val}')
#
# plt.plot(K, distortions, 'bx-')
# plt.xlabel('Values of K')
# plt.ylabel('Distortion')
# plt.title('The Elbow Method using Distortion')
# plt.show()
#
# plt.plot(K, inertias, 'bx-')
# plt.xlabel('Values of K')
# plt.ylabel('Inertia')
# plt.title('The Elbow Method using Inertia')
# plt.show()









#Create a WCSS list
wcss = []

#Finding the optimal number of clusters
for i in range (1,10):
    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)
    kmeans.fit(X)
    wcss.append(kmeans.inertia_)

#Plotting the optimal number
plt.plot(range(1,10), wcss)
plt.title('The Elbow Method Using Inertia')
plt.xlabel('Number of Clusters')
plt.ylabel('Inertia')
plt.show()

# Tenure and Monthly Charge
#Training the Method
kmeans = KMeans(n_clusters = 6, init = 'k-means++', random_state = 42)

y_kmeans = kmeans.fit_predict(X)
print('Y_Kmeans are: ',y_kmeans)

#Cluster Visualization
plt.scatter(X[y_kmeans == 0,0], X[y_kmeans == 0,1], s = 10, c = 'red', label = 'Cluster #1')
plt.scatter(X[y_kmeans == 1,0], X[y_kmeans == 1,1], s = 10, c = 'blue', label = 'Cluster #2')
plt.scatter(X[y_kmeans == 2,0], X[y_kmeans == 2,1], s = 10, c = 'orange', label = 'Cluster #3')
plt.scatter(X[y_kmeans == 3,0], X[y_kmeans == 3,1], s = 10, c = 'magenta', label = 'Cluster #4')
plt.scatter(X[y_kmeans == 4,0], X[y_kmeans == 4,1], s = 10, c = 'green', label = 'Cluster #5')
plt.scatter(X[y_kmeans == 5,0], X[y_kmeans == 5,1], s = 10, c = 'cyan', label = 'Cluster #6')

#Plot the Centroids
plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], s = 100, c = 'yellow', label = 'Centroids')
plt.xlabel('Tenure - months')
plt.ylabel('MonthlyCharge - $')
plt.title('6 Customer Clusters')
plt.show()

# #Income and Monthly Charge
# #Training the Method
# kmeans = KMeans(n_clusters = 4, init = 'k-means++', random_state = 42)
#
# y_kmeans = kmeans.fit_predict(X)
# print('Y_Kmeans are: ',y_kmeans)
#
# #Cluster Visualization
# plt.scatter(X[y_kmeans == 0,0], X[y_kmeans == 0,1], s = 10, c = 'red', label = 'Cluster #1')
# plt.scatter(X[y_kmeans == 1,0], X[y_kmeans == 1,1], s = 10, c = 'blue', label = 'Cluster #2')
# plt.scatter(X[y_kmeans == 2,0], X[y_kmeans == 2,1], s = 10, c = 'orange', label = 'Cluster #3')
# plt.scatter(X[y_kmeans == 3,0], X[y_kmeans == 3,1], s = 10, c = 'magenta', label = 'Cluster #4')
#
# #Plot the Centroids
# plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], s = 100, c = 'yellow', label = 'Centroids')
# plt.xlabel('Income - $')
# plt.ylabel('MonthlyCharge - $')
# plt.title('4 Customer Clusters')
# plt.show()

# #Tenure and Bandwidth
# #Training the Method
# kmeans = KMeans(n_clusters = 2, init = 'k-means++', random_state = 42)
#
# y_kmeans = kmeans.fit_predict(X)
# print('Y_Kmeans are: ',y_kmeans)
#
# #Cluster Visualization
# plt.scatter(X[y_kmeans == 0,0], X[y_kmeans == 0,1], s = 10, c = 'red', label = 'Cluster #1')
# plt.scatter(X[y_kmeans == 1,0], X[y_kmeans == 1,1], s = 10, c = 'blue', label = 'Cluster #2')
#
# #Plot the Centroids
# plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], s = 100, c = 'yellow', label = 'Centroids')
# plt.xlabel('Tenure - months')
# plt.ylabel('Bandwidth_GB_Year')
# plt.title('2 Customer Clusters')
# plt.show()